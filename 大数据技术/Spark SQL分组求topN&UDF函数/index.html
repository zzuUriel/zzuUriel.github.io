<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=""><link rel="stylesheet" type="text/css" href="//fonts.loli.net/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style-dark.css?v=2.0.5"><link rel="stylesheet" type="text/css" href="/css/highlight-dark.css?v=2.0.5"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><title>Spark SQL分组求topN&amp;UDF函数 | 暗也橙子Blog</title></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Spark SQL分组求topN&amp;UDF函数</h1><a id="logo" href="/.">暗也橙子Blog</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="搜索"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">Spark SQL分组求topN&amp;UDF函数</h1><div class="post-meta"><a href="/大数据技术/Spark SQL分组求topN&amp;UDF函数/#comments" class="comment-count"></a><p><span class="date">Jul 15, 2019</span><span><a href="/categories/大数据技术/" class="category">大数据技术</a></span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>点击</i></i></span></p></div><div class="post-content"><h3 id="本文介绍了用spark-sql分组求topn的方式初步了解spark-sql的使用并通过定义一个简单的udf函数让我们了解spark-sql中udf函数的定义方法">本文介绍了用Spark SQL分组求topN的方式，初步了解Spark SQL的使用，并通过定义一个简单的UDF函数，让我们了解Spark SQL中UDF函数的定义方法。</h3>
<hr>
<h4 id="分组求和">分组求和</h4>
<p>代码实现如下：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">object LogApp &#123;</span><br><span class="line">  def main(args: <span class="built_in">Array</span>[<span class="built_in">String</span>]): Unit = &#123;</span><br><span class="line">    val spark = SparkSession.builder</span><br><span class="line">      .master(<span class="string">"local"</span>)</span><br><span class="line">      .appName(<span class="keyword">this</span>.getClass.getSimpleName)</span><br><span class="line"><span class="comment">//    .enableHiveSupport() //开启HiveContext</span></span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line">    val df = spark.read.textFile(<span class="string">"ruozedata-spark-sql/data/access.log"</span>)</span><br><span class="line">        .map(<span class="function"><span class="params">x</span> =&gt;</span> &#123;</span><br><span class="line">          val splits = x.split(<span class="string">"\t"</span>)</span><br><span class="line">          val platform = splits(<span class="number">4</span>)</span><br><span class="line">          val traffic = splits(<span class="number">8</span>).toLong</span><br><span class="line">          val province = splits(<span class="number">10</span>)</span><br><span class="line">          val city = splits(<span class="number">11</span>)</span><br><span class="line">          val isp = splits(<span class="number">12</span>)</span><br><span class="line">          (platform,traffic,province,city,isp)</span><br><span class="line">        &#125;).toDF(<span class="string">"platform"</span>,<span class="string">"traffic"</span>,<span class="string">"province"</span>,<span class="string">"city"</span>,<span class="string">"isp"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//方法1，SQL方式</span></span><br><span class="line">    df.createOrReplaceTempView(<span class="string">"log"</span>)</span><br><span class="line">    spark.sql(<span class="string">"select platform,province,city,sum(traffic) as traffics from log group by platform,province,city order by traffics desc"</span>)</span><br><span class="line">        .show(<span class="literal">false</span>)</span><br><span class="line"><span class="comment">//方法2，API方式，需要导入org.apache.spark.sql.functions已经定义好的函数</span></span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line">    df.groupBy(<span class="string">"platform"</span>,<span class="string">"province"</span>,<span class="string">"city"</span>)</span><br><span class="line">        .agg(sum(<span class="string">"traffic"</span>).as(<span class="string">"traffics"</span>))</span><br><span class="line">        .sort(<span class="string">'traffics.desc)  //降序</span></span><br><span class="line"><span class="string">        .show()</span></span><br><span class="line"><span class="string">		</span></span><br><span class="line"><span class="string">    spark.stop()</span></span><br><span class="line"><span class="string">  &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure>
<p>运行结果：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+--------+--------+------+--------+</span><br><span class="line">|platform|province|city  |traffics|</span><br><span class="line">+--------+--------+------+--------+</span><br><span class="line">|Androd  |北京    |北京市|<span class="number">3606966</span> |</span><br><span class="line">|IOS     |北京    |北京市|<span class="number">3476256</span> |</span><br><span class="line">|Androd  |上海    |上海市|<span class="number">2844236</span> |</span><br><span class="line">|IOS     |上海    |上海市|<span class="number">2720308</span> |</span><br><span class="line">|IOS     |广东省  |广州市|<span class="number">1248001</span> |</span><br><span class="line">|Androd  |江苏省  |苏州市|<span class="number">1188222</span> |</span><br><span class="line">|IOS     |江苏省  |苏州市|<span class="number">1123646</span> |</span><br><span class="line">|Androd  |广东省  |广州市|<span class="number">1070594</span> |</span><br><span class="line">|IOS     |湖北省  |武汉市|<span class="number">1012666</span> |</span><br><span class="line">|Androd  |湖北省  |武汉市|<span class="number">997467</span>  |</span><br><span class="line">|IOS     |福建省  |厦门市|<span class="number">843507</span>  |</span><br><span class="line">|IOS     |福建省  |漳州市|<span class="number">817904</span>  |</span><br><span class="line">|Androd  |江苏省  |无锡市|<span class="number">801299</span>  |</span><br><span class="line">|IOS     |四川省  |成都市|<span class="number">777718</span>  |</span><br><span class="line">|Androd  |四川省  |成都市|<span class="number">774126</span>  |</span><br><span class="line">|IOS     |江苏省  |无锡市|<span class="number">769022</span>  |</span><br><span class="line">|Androd  |福建省  |厦门市|<span class="number">767532</span>  |</span><br><span class="line">|IOS     |辽宁省  |朝阳市|<span class="number">745148</span>  |</span><br><span class="line">|Androd  |福建省  |漳州市|<span class="number">719662</span>  |</span><br><span class="line">|Androd  |辽宁省  |朝阳市|<span class="number">651604</span>  |</span><br><span class="line">+--------+--------+------+--------+</span><br><span class="line">only showing top <span class="number">20</span> rows</span><br></pre></td></tr></table></figure>
<h4 id="分组求topn">分组求topN</h4>
<p>代码实现如下：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 分组求topn，SQL和API方式</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">object topNApp &#123;</span><br><span class="line">  def main(args: <span class="built_in">Array</span>[<span class="built_in">String</span>]): Unit = &#123;</span><br><span class="line">    val spark = SparkSession.builder</span><br><span class="line">      .master(<span class="string">"local"</span>)</span><br><span class="line">      .appName(<span class="keyword">this</span>.getClass.getSimpleName)</span><br><span class="line"><span class="comment">//    .enableHiveSupport() //开启HiveContext</span></span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line">    val df = spark.read.textFile(<span class="string">"ruozedata-spark-sql/data/access.log"</span>)</span><br><span class="line">        .map(<span class="function"><span class="params">x</span> =&gt;</span> &#123;</span><br><span class="line">          val splits = x.split(<span class="string">"\t"</span>)</span><br><span class="line">          val platform = splits(<span class="number">4</span>)</span><br><span class="line">          val traffic = splits(<span class="number">8</span>).toLong</span><br><span class="line">          val province = splits(<span class="number">10</span>)</span><br><span class="line">          val city = splits(<span class="number">11</span>)</span><br><span class="line">          val isp = splits(<span class="number">12</span>)</span><br><span class="line">          (platform,traffic,province,city,isp)</span><br><span class="line">        &#125;).toDF(<span class="string">"platform"</span>,<span class="string">"traffic"</span>,<span class="string">"province"</span>,<span class="string">"city"</span>,<span class="string">"isp"</span>)</span><br><span class="line"></span><br><span class="line">    df.createOrReplaceTempView(<span class="string">"log"</span>)</span><br><span class="line">    <span class="comment">// 方法1:按照platform分组，province访问次数最多的TopN,SQL方式</span></span><br><span class="line">    val topNSQL =<span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">        |select * from</span></span><br><span class="line"><span class="string">        |(</span></span><br><span class="line"><span class="string">        |select t.*,row_number() over(partition by platform order by cnt desc) as rank</span></span><br><span class="line"><span class="string">        |from</span></span><br><span class="line"><span class="string">        |(select platform,province,city,count(1) cnt from log group by platform,province,city) t</span></span><br><span class="line"><span class="string">        |) a where a.rank&lt;3</span></span><br><span class="line"><span class="string">        |"</span><span class="string">""</span>.stripMargin</span><br><span class="line"></span><br><span class="line">    spark.sql(topNSQL).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 方法2：按照platform分组，province访问次数最多的TopN,API方式</span></span><br><span class="line"></span><br><span class="line">    val df2 = df.groupBy(<span class="string">"platform"</span>, <span class="string">"province"</span>, <span class="string">"city"</span>).count()</span><br><span class="line"></span><br><span class="line">    val windowRule: WindowSpec = Window.partitionBy(<span class="string">"platform"</span>).orderBy($<span class="string">"count"</span>.desc)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line">    df2.withColumn(<span class="string">"rank"</span>,row_number().over(windowRule)).where(<span class="string">"rank&lt;3"</span>).show()</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>运行结果：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">+--------+--------+------+-----+----+</span><br><span class="line">|platform|province|  city|count|rank|</span><br><span class="line">+--------+--------+------+-----+----+</span><br><span class="line">|  Androd|    北京|北京市| <span class="number">1200</span>|   <span class="number">1</span>|</span><br><span class="line">|  Androd|    上海|上海市|  <span class="number">953</span>|   <span class="number">2</span>|</span><br><span class="line">|     IOS|    北京|北京市| <span class="number">1164</span>|   <span class="number">1</span>|</span><br><span class="line">|     IOS|    上海|上海市|  <span class="number">911</span>|   <span class="number">2</span>|</span><br><span class="line">+--------+--------+------+-----+----+</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Process finished <span class="keyword">with</span> exit code <span class="number">0</span></span><br></pre></td></tr></table></figure>
<h4 id="udf函数">UDF函数</h4>
<p>1、数据</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">大狗	小破车,渣团,热刺,我纯</span><br><span class="line">桶子	利物浦</span><br><span class="line">二条	南大王,西班牙人</span><br></pre></td></tr></table></figure>
<p>2、需求：求出每个人的爱好个数。（大狗4，桶子1，二娃2）<br>
3、实现</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 定义UDF函数</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">object UDFApp &#123;</span><br><span class="line"></span><br><span class="line">  def main(args: <span class="built_in">Array</span>[<span class="built_in">String</span>]): Unit = &#123;</span><br><span class="line">    val spark = SparkSession.builder</span><br><span class="line">      .master(<span class="string">"local"</span>)</span><br><span class="line">      .appName(<span class="keyword">this</span>.getClass.getSimpleName)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line">    val df = spark.sparkContext.textFile(<span class="string">"ruozedata-spark-sql/data/likes.txt"</span>)</span><br><span class="line">      .map(_.split(<span class="string">"\t"</span>))</span><br><span class="line">      .map(<span class="function"><span class="params">x</span> =&gt;</span> Likes(x(<span class="number">0</span>), x(<span class="number">1</span>)))</span><br><span class="line">      .toDF</span><br><span class="line"></span><br><span class="line">    df.createOrReplaceTempView(<span class="string">"likes"</span>)</span><br><span class="line"><span class="comment">//定义UDF函数</span></span><br><span class="line">    val teamsLengthUDF = spark.udf.register(<span class="string">"teams_length"</span>,(input:<span class="built_in">String</span>) =&gt;&#123;</span><br><span class="line">      input.split(<span class="string">","</span>).length</span><br><span class="line">    &#125;)</span><br><span class="line"><span class="comment">//方法1：SQL方式</span></span><br><span class="line">    spark.sql(<span class="string">"select name,teams,teams_length(teams) as teams_length from likes"</span>).show(<span class="literal">false</span>)</span><br><span class="line"><span class="comment">//方法2：API方式</span></span><br><span class="line">    df.select($<span class="string">"name"</span>,$<span class="string">"teams"</span>,teamsLengthUDF($<span class="string">"teams"</span>)).show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br><span class="line">  &#125;</span><br><span class="line">  case class Likes(name: String, teams: String)</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>4.运行结果</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+----+---------------------+-----------------------+</span><br><span class="line">|name|teams                |UDF:teams_length(teams)|</span><br><span class="line">+----+---------------------+-----------------------+</span><br><span class="line">|pk  |小破车,查团,热刺,我纯|<span class="number">4</span>                      |</span><br><span class="line">|桶子|利物浦               |<span class="number">1</span>                      |</span><br><span class="line">|二娃|男大王,西班牙人      |<span class="number">2</span>                      |</span><br><span class="line">+----+---------------------+-----------------------+</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Process finished <span class="keyword">with</span> exit code <span class="number">0</span></span><br></pre></td></tr></table></figure>
</div><div class="post-copyright"><blockquote><p>原文作者: 暗也橙子</p><p>原文链接: <a href="https://zzuuriel.github.io/大数据技术/Spark SQL分组求topN&amp;UDF函数/">https://zzuuriel.github.io/大数据技术/Spark SQL分组求topN&amp;UDF函数/</a></p><p>版权声明: 转载请注明出处(必须保留作者署名及链接)</p></blockquote></div><div class="tags"><a href="/tags/Spark/">Spark</a></div><div class="post-share"><div class="social-share"><span>分享到:</span></div></div><div class="post-nav"><a href="/大数据技术/Spark SQL之RDD转换DataFrame&amp;DF和DS的转换&amp;跨数据源操作&amp;用SQL方式操作数据源&amp;元数据catalog/" class="pre">Spark SQL之RDD转换DataFrame&amp;DF和DS的转换&amp;跨数据源操作&amp;用SQL方式操作数据源&amp;元数据catalog</a><a href="/大数据技术/8.spark工作模式详解(localstandaloneyarn)/" class="next"> Spark工作模式详解(local/standalone/yarn) </a></div><div id="comments"></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#本文介绍了用spark-sql分组求topn的方式初步了解spark-sql的使用并通过定义一个简单的udf函数让我们了解spark-sql中udf函数的定义方法"><span class="toc-text">&#x672C;&#x6587;&#x4ECB;&#x7ECD;&#x4E86;&#x7528;Spark SQL&#x5206;&#x7EC4;&#x6C42;topN&#x7684;&#x65B9;&#x5F0F;&#xFF0C;&#x521D;&#x6B65;&#x4E86;&#x89E3;Spark SQL&#x7684;&#x4F7F;&#x7528;&#xFF0C;&#x5E76;&#x901A;&#x8FC7;&#x5B9A;&#x4E49;&#x4E00;&#x4E2A;&#x7B80;&#x5355;&#x7684;UDF&#x51FD;&#x6570;&#xFF0C;&#x8BA9;&#x6211;&#x4EEC;&#x4E86;&#x89E3;Spark SQL&#x4E2D;UDF&#x51FD;&#x6570;&#x7684;&#x5B9A;&#x4E49;&#x65B9;&#x6CD5;&#x3002;</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#分组求和"><span class="toc-text">&#x5206;&#x7EC4;&#x6C42;&#x548C;</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#分组求topn"><span class="toc-text">&#x5206;&#x7EC4;&#x6C42;topN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#udf函数"><span class="toc-text">UDF&#x51FD;&#x6570;</span></a></li></ol></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/大数据技术/修改Flume源码使taildir source支持递归（可配置）/">修改Flume源码使taildir source支持递归（可配置）</a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/解决Spark on YARN时jar包乱飞的问题/">解决Spark on YARN时jar包乱飞的问题</a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/Flink之Watermark理解/">Flink之Watermark理解</a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/2.spark-2.4.5-bin-2.6.0-cdh5.15.1.tgz/"> Spark-2.4.5源码编译</a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/Flink自定义触发器/">Flink自定义触发器</a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/60.深入理解Spark算子aggregate/">深入理解Spark算子aggregate</a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/60.Kudu常用Api(java)/">Kudu常用Api(java) </a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/60.CentOS7安装单机版Kudu/">CentOS7安装单机版Kudu </a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/HBase架构和读写流程/">HBase架构和读写流程</a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/HBase的Rowkey设计/">HBase的Rowkey设计</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-gui"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Linux基础/">Linux基础</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Scala编程语言/">Scala编程语言</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/大数据技术/">大数据技术</a><span class="category-list-count">39</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据结构与算法/">数据结构与算法</a><span class="category-list-count">1</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="/tags/Spark/" style="font-size: 15px;">Spark</a> <a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/Scala/" style="font-size: 15px;">Scala</a> <a href="/tags/Kudu/" style="font-size: 15px;">Kudu</a> <a href="/tags/Flink/" style="font-size: 15px;">Flink</a> <a href="/tags/HBase/" style="font-size: 15px;">HBase</a> <a href="/tags/Hive/" style="font-size: 15px;">Hive</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/Shell/" style="font-size: 15px;">Shell</a> <a href="/tags/Kafka/" style="font-size: 15px;">Kafka</a> <a href="/tags/Flume/" style="font-size: 15px;">Flume</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/">2020</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/">2019</a><span class="archive-list-count">45</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/">2018</a><span class="archive-list-count">6</span></li></ul></div></div></div></div><a id="totop" href="#top"></a><div id="footer"> <div class="footer-info"><p><a href="/baidusitemap.xml">网站地图</a> |  <a href="/atom.xml">订阅本站</a> |  <a href="/about/">联系博主</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次，本站总访客数:<i id="busuanzi_container_site_uv"><i id="busuanzi_value_site_uv"></i></i>人</p><p><span> Copyright &copy;<a href="/." rel="nofollow">暗也橙子.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/zzuUriel/zzuUriel.github.io"> BlueLake.</a></span><span> Count by<a href="http://busuanzi.ibruce.info/"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/javascript" src="/js/search.json.js?v=2.0.5"></script><div id="fullscreen-img" class="hide"><span class="close"></span></div><script type="text/javascript" src="/js/imgview.js?v=2.0.5" async></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.5" async></script><link rel="stylesheet" type="text/css" href="/share/css/share.css"><script type="text/javascript" src="/share/js/social-share.js" charset="utf-8"></script><script type="text/javascript" src="/share/js/qrcode.js" charset="utf-8"></script></body></html>