<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=""><link rel="stylesheet" type="text/css" href="//fonts.loli.net/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style-dark.css?v=2.0.5"><link rel="stylesheet" type="text/css" href="/css/highlight-dark.css?v=2.0.5"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><title>CDH5.16.1安装Spark2.x，简称CDS安装 | 暗也橙子Blog</title></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">CDH5.16.1安装Spark2.x，简称CDS安装</h1><a id="logo" href="/.">暗也橙子Blog</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="搜索"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">CDH5.16.1安装Spark2.x，简称CDS安装</h1><div class="post-meta"><a href="/大数据技术/CDH5.16.1安装Spark2.x，简称CDS安装/#comments" class="comment-count"></a><p><span class="date">Oct 26, 2019</span><span><a href="/categories/大数据技术/" class="category">大数据技术</a></span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>点击</i></i></span></p></div><div class="post-content"><h3 id="cdh5161安装spark2x简称cds安装">CDH5.16.1安装Spark2.x，简称CDS安装</h3>
<hr>
<h4 id="官方文档">官方文档</h4>
<p>官网的文档地址：<a href="https://docs.cloudera.com/documentation/" target="_blank" rel="noopener">https://docs.cloudera.com/documentation/</a><br>
<img src="/img/CDH/CDH-spark01.png" alt="CDH-spark01.png"><br>
点击上面的Apache Spark2<br>
<img src="/img/CDH/CDH-spark02.png" alt="CDH-spark02.png"><br>
如下图，第一点是安装Spark的一些版本要求，我们点进去看下<br>
<img src="/img/CDH/CDH-spark03.png" alt="CDH-spark03.png"><br>
如下图，是安装spark之前的一些版本要求，自己去看下对应关系<br>
<img src="/img/CDH/CDH-spark04.png" alt="CDH-spark04.png"></p>
<h4 id="安装cds">安装CDS</h4>
<h5 id="安装service-descriptor">安装Service Descriptor</h5>
<p>步骤a<br>
<img src="/img/CDH/CDH-spark05.png" alt="CDH-spark05.png"><br>
先要安装service descriptor，我们点击链接进去看看<br>
<img src="/img/CDH/CDH-spark06.png" alt="CDH-spark06.png"><br>
先下载service descriptor</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http:<span class="comment">//archive.cloudera.com/spark2/csd/SPARK2_ON_YARN-2.4.0.cloudera2.jar</span></span><br></pre></td></tr></table></figure>
<p>然后顺便把包裹Parcel也下载了，点击右边的链接<br>
<img src="/img/CDH/CDH-spark07.png" alt="CDH-spark07.png"><br>
下载命令</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget http:<span class="comment">//archive.cloudera.com/spark2/parcels/2.4.0.cloudera2/SPARK2-2.4.0.cloudera2-1.cdh5.13.3.p0.1041012-el7.parcel</span></span><br><span class="line">wget http:<span class="comment">//archive.cloudera.com/spark2/parcels/2.4.0.cloudera2/SPARK2-2.4.0.cloudera2-1.cdh5.13.3.p0.1041012-el7.parcel.sha1</span></span><br><span class="line">wget http:<span class="comment">//archive.cloudera.com/spark2/parcels/2.4.0.cloudera2/manifest.json</span></span><br></pre></td></tr></table></figure>
<p>下载之后的文件<br>
<img src="/img/CDH/CDH-spark08.png" alt="CDH-spark08.png"></p>
<p>步骤b<br>
然后我们接着安装service descriptor，刚刚步骤a我们已经下载好了<br>
<img src="/img/CDH/CDH-spark09.png" alt="CDH-spark09.png"><br>
从上图可以看出，步骤b是让我们登陆到Cloudera Manager Server主机，然后把下载好的service descriptor拷贝到location configured，我们点进去看看位置在哪里<br>
<img src="/img/CDH/CDH-spark10.png" alt="CDH-spark10.png"><br>
创建目录</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir /opt/cloudera/csd</span><br></pre></td></tr></table></figure>
<p>移动service descriptor文件</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv SPARK2_ON_YARN<span class="number">-2.4</span><span class="number">.0</span>.cloudera2.jar /opt/cloudera/csd</span><br></pre></td></tr></table></figure>
<p>步骤c<br>
<img src="/img/CDH/CDH-spark11.png" alt="CDH-spark11.png"><br>
设置service descriptor文件的拥有者和权限644</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chown -R cloudera-scm:cloudera-scm /opt/cloudera/csd/SPARK2_ON_YARN<span class="number">-2.4</span><span class="number">.0</span>.cloudera2.jar</span><br><span class="line">chmod -R <span class="number">644</span> /opt/cloudera/csd/SPARK2_ON_YARN<span class="number">-2.4</span><span class="number">.0</span>.cloudera2.jar</span><br></pre></td></tr></table></figure>
<p>步骤d<br>
重启Cloudera Manager Server</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl restart cloudera-scm-server</span><br></pre></td></tr></table></figure>
<h5 id="添加包裹仓库parcel-repository">添加包裹仓库(parcel repository)</h5>
<p>第二点，我们已经做了，下面我们看第三点<br>
<img src="/img/CDH/CDH-spark12.png" alt="CDH-spark12.png"><br>
上面描述，在CM管理员控制界面，添加远程仓库URL，我们看下面的Note注意：如果我们的CMS不能互联网访问，可以把parcel文件放到一个新的仓库，也就是我们自己内部搭建一个仓库地址，然后内网安装（因为有的企业只能内网集群），我们点击new parcel repository<br>
<img src="/img/CDH/CDH-spark13.png" alt="CDH-spark13.png"><br>
下面我们就跟着官网一起配置自己的http服务<br>
先安装httpd</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install -y httpd</span><br></pre></td></tr></table></figure>
<p>然后启动httpd</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl start httpd</span><br></pre></td></tr></table></figure>
<p>下面这一步是要我们下载parcel和manifest.json,这个下载，我们刚刚在前面已经下载了<br>
<img src="/img/CDH/CDH-spark14.png" alt="CDH-spark14.png"><br>
下图，让我们把.parcel文件和manifest.json文件移动到我们刚刚安装的httpd server目录<br>
<img src="/img/CDH/CDH-spark15.png" alt="CDH-spark15.png"><br>
然后我们执行下面的命令：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir /<span class="keyword">var</span>/www/html/spark2_parcel</span><br><span class="line">sudo mv *.parcel* <span class="regexp">/var/</span>www/html/spark2_parcel</span><br><span class="line">sudo mv manifest.json /<span class="keyword">var</span>/www/html/spark2_parcel</span><br><span class="line">sudo chmod -R ugo+rX /<span class="keyword">var</span>/www/html/spark2_parcel</span><br></pre></td></tr></table></figure>
<p>然后我们查看httpd服务，看能不能访问到parcel<br>
<img src="/img/CDH/CDH-spark16.png" alt="CDH-spark16.png"><br>
从下图可以看出，我们自己的parcel repository搭建好了<br>
<img src="/img/CDH/CDH-spark17.png" alt="CDH-spark17.png"></p>
<h5 id="cms配置parcel-url">CMS配置Parcel URL</h5>
<p>继续看官网的操作说明<br>
<img src="/img/CDH/CDH-spark18.png" alt="CDH-spark18.png"><br>
进入cloudera manager界面 点击Parcels<br>
<img src="/img/CDH/CDH-spark19.png" alt="CDH-spark19.png"><br>
点击Configuration<br>
<img src="/img/CDH/CDH-spark20.png" alt="CDH-spark20.png"><br>
然后我们继续看看官网说怎么配置<br>
<img src="/img/CDH/CDH-spark21.png" alt="CDH-spark21.png"><br>
意思是让我们输入我们自己的httpd搭建好的包裹文件路径，然后保证Changes<br>
<img src="/img/CDH/CDH-spark22.png" alt="CDH-spark22.png"><br>
到这里可以看到Spark,本地URL已经设置好了<br>
<img src="/img/CDH/CDH-spark23.png" alt="CDH-spark23.png"></p>
<h5 id="添加spark2-服务">添加Spark2 服务</h5>
<p>点击Add Service<br>
<img src="/img/CDH/CDH-spark24.png" alt="CDH-spark24.png"><br>
spark2出现了<br>
<img src="/img/CDH/CDH-spark25.png" alt="CDH-spark25.png"><br>
选择History Server节点<br>
<img src="/img/CDH/CDH-spark26.png" alt="CDH-spark26.png"><br>
选择hadoop003，因为其他机器服务较多，以后提交spark作业，到hadoop003提交即可。<br>
<img src="/img/CDH/CDH-spark27.png" alt="CDH-spark27.png"><br>
然后一直下一步即可<br>
最后重启下yarn即可，因为yarn不仅要支持mapreduce,还要支持spark on yarn<br>
<img src="/img/CDH/CDH-spark28.png" alt="CDH-spark28.png"><br>
到这里安装结束</p>
<h4 id="运行example">运行example</h4>
<p>cloudera公司Spark的文档：<a href="https://docs.cloudera.com/documentation/spark2/latest.html" target="_blank" rel="noopener">https://docs.cloudera.com/documentation/spark2/latest.html</a><br>
<img src="/img/CDH/CDH-spark29.png" alt="CDH-spark29.png"><br>
点进去看看,spark2的命令为spark2-submit<br>
<img src="/img/CDH/CDH-spark30.png" alt="CDH-spark30.png"><br>
用CRT连接hadoop003机器，因为我们刚刚在hadoop003安装spark2的</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spark2-submit \</span><br><span class="line">--master yarn \</span><br><span class="line">--executor-memory <span class="number">1</span>G \</span><br><span class="line">--executor-cores <span class="number">1</span> \</span><br><span class="line">--num-executors <span class="number">1</span> \</span><br><span class="line">--<span class="class"><span class="keyword">class</span> <span class="title">org</span>.<span class="title">apache</span>.<span class="title">spark</span>.<span class="title">examples</span>.<span class="title">SparkPi</span> \</span></span><br><span class="line"><span class="class">/<span class="title">opt</span>/<span class="title">cloudera</span>/<span class="title">parcels</span>/<span class="title">SPARK2</span>/<span class="title">lib</span>/<span class="title">spark2</span>/<span class="title">examples</span>/<span class="title">jars</span>/<span class="title">spark</span>-<span class="title">examples_2</span>.11-2.4.0.<span class="title">cloudera2</span>.<span class="title">jar</span></span></span><br></pre></td></tr></table></figure>
<p>执行的时候出现如下的错误(遇到错误的时候，不要害怕，看日志)：<br>
Exception in thread “main” java.lang.IllegalArgumentException: Required executor memory (1024), overhead (384 MB), and PySpark memory (0 MB) is above the max threshold (1208 MB) of this cluster! Please check the values of ‘yarn.scheduler.maximum-allocation-mb’ and/or ‘yarn.nodemanager.resource.memory-mb’<br>
从上面错误可以看出，是内存不够，而且上面已经给我们提示，这个参数需要检查一下<br>
<img src="/img/CDH/CDH-spark31.png" alt="CDH-spark31.png"><br>
再设置下Container内存，因为executor是跑在Container里的<br>
<img src="/img/CDH/CDH-spark32.png" alt="CDH-spark32.png"><br>
重启yarn之后，我们再执行</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spark2-submit \</span><br><span class="line">--master yarn \</span><br><span class="line">--executor-memory <span class="number">1</span>G \</span><br><span class="line">--executor-cores <span class="number">1</span> \</span><br><span class="line">--num-executors <span class="number">1</span> \</span><br><span class="line">--<span class="class"><span class="keyword">class</span> <span class="title">org</span>.<span class="title">apache</span>.<span class="title">spark</span>.<span class="title">examples</span>.<span class="title">SparkPi</span> \</span></span><br><span class="line"><span class="class">/<span class="title">opt</span>/<span class="title">cloudera</span>/<span class="title">parcels</span>/<span class="title">SPARK2</span>/<span class="title">lib</span>/<span class="title">spark2</span>/<span class="title">examples</span>/<span class="title">jars</span>/<span class="title">spark</span>-<span class="title">examples_2</span>.11-2.4.0.<span class="title">cloudera2</span>.<span class="title">jar</span></span></span><br></pre></td></tr></table></figure>
<p>发现又出现如下错误：<br>
<img src="/img/CDH/CDH-spark33.png" alt="CDH-spark33.png"><br>
org.apache.hadoop.security.AccessControlException: Permission denied: user=root, access=WRITE, inode=&quot;/user&quot;:hdfs:supergroup:drwxr-xr-x<br>
上面错误的意思是：权限拒绝，我们使用的用户root，期望进行写的操作<br>
但是节点只允许hdfs用户，进行写，那么我们切换到hdfs去执行名<br>
执行结果如下，说明我们的spark2可以正常使用<br>
<img src="/img/CDH/CDH-spark34.png" alt="CDH-spark34.png"></p>
</div><div class="post-copyright"><blockquote><p>原文作者: 暗也橙子</p><p>原文链接: <a href="https://zzuuriel.github.io/大数据技术/CDH5.16.1安装Spark2.x，简称CDS安装/">https://zzuuriel.github.io/大数据技术/CDH5.16.1安装Spark2.x，简称CDS安装/</a></p><p>版权声明: 转载请注明出处(必须保留作者署名及链接)</p></blockquote></div><div class="tags"><a href="/tags/Spark/">Spark</a><a href="/tags/CDH/">CDH</a></div><div class="post-share"><div class="social-share"><span>分享到:</span></div></div><div class="post-nav"><a href="/大数据技术/60.CentOS7安装单机版Kudu/" class="pre">CentOS7安装单机版Kudu </a><a href="/大数据技术/CDH安装Kafka,简称CDK安装/" class="next">CDH安装Kafka</a></div><div id="comments"></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#cdh5161安装spark2x简称cds安装"><span class="toc-text">CDH5.16.1&#x5B89;&#x88C5;Spark2.x&#xFF0C;&#x7B80;&#x79F0;CDS&#x5B89;&#x88C5;</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#官方文档"><span class="toc-text">&#x5B98;&#x65B9;&#x6587;&#x6863;</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#安装cds"><span class="toc-text">&#x5B89;&#x88C5;CDS</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#安装service-descriptor"><span class="toc-text">&#x5B89;&#x88C5;Service Descriptor</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#添加包裹仓库parcel-repository"><span class="toc-text">&#x6DFB;&#x52A0;&#x5305;&#x88F9;&#x4ED3;&#x5E93;(parcel repository)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#cms配置parcel-url"><span class="toc-text">CMS&#x914D;&#x7F6E;Parcel URL</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#添加spark2-服务"><span class="toc-text">&#x6DFB;&#x52A0;Spark2 &#x670D;&#x52A1;</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#运行example"><span class="toc-text">&#x8FD0;&#x884C;example</span></a></li></ol></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/大数据技术/修改Flume源码使taildir source支持递归（可配置）/">修改Flume源码使taildir source支持递归（可配置）</a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/解决Spark on YARN时jar包乱飞的问题/">解决Spark on YARN时jar包乱飞的问题</a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/Flink之Watermark理解/">Flink之Watermark理解</a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/2.spark-2.4.5-bin-2.6.0-cdh5.15.1.tgz/"> Spark-2.4.5源码编译</a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/Flink自定义触发器/">Flink自定义触发器</a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/60.深入理解Spark算子aggregate/">深入理解Spark算子aggregate</a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/60.Kudu常用Api(java)/">Kudu常用Api(java) </a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/60.CentOS7安装单机版Kudu/">CentOS7安装单机版Kudu </a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/CDH5.16.1安装Spark2.x，简称CDS安装/">CDH5.16.1安装Spark2.x，简称CDS安装</a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/CDH安装Kafka,简称CDK安装/">CDH安装Kafka</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-gui"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Linux基础/">Linux基础</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Scala编程语言/">Scala编程语言</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/大数据技术/">大数据技术</a><span class="category-list-count">41</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据结构与算法/">数据结构与算法</a><span class="category-list-count">6</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/Spark/" style="font-size: 15px;">Spark</a> <a href="/tags/Scala/" style="font-size: 15px;">Scala</a> <a href="/tags/Kudu/" style="font-size: 15px;">Kudu</a> <a href="/tags/CDH/" style="font-size: 15px;">CDH</a> <a href="/tags/Kafka/" style="font-size: 15px;">Kafka</a> <a href="/tags/Flink/" style="font-size: 15px;">Flink</a> <a href="/tags/HBase/" style="font-size: 15px;">HBase</a> <a href="/tags/Hive/" style="font-size: 15px;">Hive</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/Shell/" style="font-size: 15px;">Shell</a> <a href="/tags/Flume/" style="font-size: 15px;">Flume</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/">2020</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/">2019</a><span class="archive-list-count">52</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/">2018</a><span class="archive-list-count">6</span></li></ul></div></div></div></div><a id="totop" href="#top"></a><div id="footer"> <div class="footer-info"><p><a href="/baidusitemap.xml">网站地图</a> |  <a href="/atom.xml">订阅本站</a> |  <a href="/about/">联系博主</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次，本站总访客数:<i id="busuanzi_container_site_uv"><i id="busuanzi_value_site_uv"></i></i>人</p><p><span> Copyright &copy;<a href="/." rel="nofollow">暗也橙子.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/zzuUriel/zzuUriel.github.io"> BlueLake.</a></span><span> Count by<a href="http://busuanzi.ibruce.info/"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/javascript" src="/js/search.json.js?v=2.0.5"></script><div id="fullscreen-img" class="hide"><span class="close"></span></div><script type="text/javascript" src="/js/imgview.js?v=2.0.5" async></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.5" async></script><link rel="stylesheet" type="text/css" href="/share/css/share.css"><script type="text/javascript" src="/share/js/social-share.js" charset="utf-8"></script><script type="text/javascript" src="/share/js/qrcode.js" charset="utf-8"></script></body></html>