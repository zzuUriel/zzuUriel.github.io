<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=""><link rel="stylesheet" type="text/css" href="//fonts.loli.net/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style-dark.css?v=2.0.5"><link rel="stylesheet" type="text/css" href="/css/highlight-dark.css?v=2.0.5"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><title>Spark Core之读写数据 | 暗也橙子Blog</title></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Spark Core之读写数据</h1><a id="logo" href="/.">暗也橙子Blog</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="搜索"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">Spark Core之读写数据</h1><div class="post-meta"><a href="/大数据技术/Spark Core之读写数据/#comments" class="comment-count"></a><p><span class="date">Jun 06, 2019</span><span><a href="/categories/大数据技术/" class="category">大数据技术</a></span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>点击</i></i></span></p></div><div class="post-content"><h3 id="spark-core之读写数据">Spark Core之读写数据</h3>
<hr>
<p>Spark支持多种数据源，从总体来分分为两大部分：文件系统和数据库。</p>
<h4 id="文件系统">文件系统</h4>
<p>文件系统主要有本地文件系统、Amazon S3、HDFS等。<br>
文件系统中存储的文件有多种存储格式。Spark支持的一些常见格式有：</p>
<table>
<thead>
<tr>
<th>格式名称</th>
<th>结构化</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>文本文件</td>
<td>否</td>
<td>普通文本文件，每行一条记录</td>
</tr>
<tr>
<td>JSON</td>
<td>半结构化</td>
<td>常见的基于文本的半结构化数据</td>
</tr>
<tr>
<td>CSV</td>
<td>是</td>
<td>常见的基于文本的格式，在电子表格应用中使用</td>
</tr>
<tr>
<td>SequenceFiles</td>
<td>是</td>
<td>一种用于键值对数据的常见Hadoop文件格式</td>
</tr>
</tbody>
</table>
<p>以文本文件为例：<br>
1.读取<br>
读取单个文件，参数为文件全路径，输入的每一行都会成为RDD的一个元素。</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val lines = sc.textFile(<span class="string">"spark-core/data/cdnlog.txt"</span>)</span><br></pre></td></tr></table></figure>
<p>读取多个文件时，可以使用textFile将参数改为目录或以逗号文件的多个文件名。如果是小文件，也可以使用wholeTextFiles读取为一个Pair RDD（键是文件名，值是文件内容）。</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">val input = sc.wholeTextFiles(<span class="string">"spark-core/data/test.txt"</span>)</span><br><span class="line">val result = input.mapValues&#123;</span><br><span class="line">    y =&gt; &#123;</span><br><span class="line">        val nums = y.split(<span class="string">" "</span>).map(<span class="function"><span class="params">x</span> =&gt;</span> x.toDouble)</span><br><span class="line">        nums.sum / nums.size.toDouble</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>2.写入<br>
输出文本文件时，可使用saveAsTextFile()方法接收一个目录，将RDD中的内容输出到目录中的多个文件中。</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result.saveAsTextFile(outputFile)</span><br></pre></td></tr></table></figure>
<h4 id="数据库">数据库</h4>
<p>数据库主要分为关系型数据库（MySQL、PostgreSQL等）和非关系型数据库（HBase、ElasticSearch等）。Spark使用JDBC访问关系型数据库（MySQL、PostgreSQL等），只需要构建一个org.apache.spark.rdd.JdbcRDD即可。<br>
以MySQL为例：<br>
1.读取：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def readMySQL(sc: SparkContext) = &#123;</span><br><span class="line"></span><br><span class="line">  val stat: JdbcRDD[<span class="function">(<span class="params"><span class="built_in">String</span>, Int</span>)] = <span class="params">new</span> <span class="params">JdbcRDD</span>(<span class="params">sc, (</span>) =&gt;</span> &#123;</span><br><span class="line">    DriverManager.getConnection(<span class="string">"jdbc:mysql://hadoop000:3306/ruozedata_spark_online"</span>, <span class="string">"root"</span>, <span class="string">"123456"</span>)</span><br><span class="line">  &#125;,</span><br><span class="line">    sql = <span class="string">"select * from stat where cnt &gt;= ? and cnt &lt;= ?"</span></span><br><span class="line"> , lowerBound = <span class="number">40</span>, upperBound = <span class="number">110</span>, numPartitions = <span class="number">1</span></span><br><span class="line">    resultSet =&gt; (resultSet.getString(<span class="number">1</span>), resultSet.getInt(<span class="number">2</span>))</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">  println(<span class="string">"count: "</span> + stat.count())</span><br><span class="line">  stat.foreach(println)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>2.写入:</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">def saveMySQL(sc: SparkContext) = &#123;</span><br><span class="line"></span><br><span class="line">  val rdd = sc.parallelize(<span class="built_in">Array</span>((<span class="string">"BJ"</span>,<span class="number">100</span>),(<span class="string">"SH"</span>,<span class="number">10</span>),(<span class="string">"SZ"</span>,<span class="number">30</span>)),<span class="number">1</span>)</span><br><span class="line">	</span><br><span class="line">  rdd.foreachPartition(<span class="function"><span class="params">partition</span> =&gt;</span> &#123;</span><br><span class="line">    val connection = DriverManager.getConnection(<span class="string">"jdbc:mysql://hadoop000:3306/ruozedata_spark_online"</span>,<span class="string">"root"</span>,<span class="string">"123456"</span>)</span><br><span class="line">    println(<span class="string">"---------------------"</span>)</span><br><span class="line">    connection.setAutoCommit(<span class="literal">false</span>)</span><br><span class="line">    <span class="comment">//表名stat,列名province, cnt</span></span><br><span class="line">    val pstmt = connection.prepareStatement(<span class="string">"ins(province, cnt) ert into stat values (?,?)"</span>)</span><br><span class="line">    partition.foreach(<span class="function"><span class="params">x</span> =&gt;</span> &#123;</span><br><span class="line">      pstmt.setString(<span class="number">1</span>, x._1)</span><br><span class="line">      pstmt.setInt(<span class="number">2</span>, x._2)</span><br><span class="line">      <span class="comment">//批处理</span></span><br><span class="line">      pstmt.addBatch()</span><br><span class="line">    &#125;)</span><br><span class="line">    pstmt.executeBatch()</span><br><span class="line">    connection.commit()</span><br><span class="line">    connection.close()</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</div><div class="post-copyright"><blockquote><p>原文作者: 暗也橙子</p><p>原文链接: <a href="https://zzuuriel.github.io/大数据技术/Spark Core之读写数据/">https://zzuuriel.github.io/大数据技术/Spark Core之读写数据/</a></p><p>版权声明: 转载请注明出处(必须保留作者署名及链接)</p></blockquote></div><div class="tags"><a href="/tags/Spark/">Spark</a></div><div class="post-share"><div class="social-share"><span>分享到:</span></div></div><div class="post-nav"><a href="/大数据技术/Spark中job、stage、task的划分/" class="pre">Spark中job、stage、task的划分</a><a href="/大数据技术/Spark Core基础-常用算子/" class="next">Spark Core基础-常用算子</a></div><div id="comments"></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#spark-core之读写数据"><span class="toc-text">Spark Core&#x4E4B;&#x8BFB;&#x5199;&#x6570;&#x636E;</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#文件系统"><span class="toc-text">&#x6587;&#x4EF6;&#x7CFB;&#x7EDF;</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#数据库"><span class="toc-text">&#x6570;&#x636E;&#x5E93;</span></a></li></ol></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/大数据技术/修改Flume源码使taildir source支持递归（可配置）/">修改Flume源码使taildir source支持递归（可配置）</a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/解决Spark on YARN时jar包乱飞的问题/">解决Spark on YARN时jar包乱飞的问题</a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/Flink之Watermark理解/">Flink之Watermark理解</a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/2.spark-2.4.5-bin-2.6.0-cdh5.15.1.tgz/"> Spark-2.4.5源码编译</a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/Flink自定义触发器/">Flink自定义触发器</a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/60.深入理解Spark算子aggregate/">深入理解Spark算子aggregate</a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/60.Kudu常用Api(java)/">Kudu常用Api(java) </a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/60.CentOS7安装单机版Kudu/">CentOS7安装单机版Kudu </a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/HBase架构和读写流程/">HBase架构和读写流程</a></li><li class="post-list-item"><a class="post-list-link" href="/大数据技术/HBase的Rowkey设计/">HBase的Rowkey设计</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-gui"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Linux基础/">Linux基础</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Scala编程语言/">Scala编程语言</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/大数据技术/">大数据技术</a><span class="category-list-count">26</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/Spark/" style="font-size: 15px;">Spark</a> <a href="/tags/Scala/" style="font-size: 15px;">Scala</a> <a href="/tags/Kudu/" style="font-size: 15px;">Kudu</a> <a href="/tags/Flink/" style="font-size: 15px;">Flink</a> <a href="/tags/HBase/" style="font-size: 15px;">HBase</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/Shell/" style="font-size: 15px;">Shell</a> <a href="/tags/Flume/" style="font-size: 15px;">Flume</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/">2020</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/">2019</a><span class="archive-list-count">31</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/">2018</a><span class="archive-list-count">2</span></li></ul></div></div></div></div><a id="totop" href="#top"></a><div id="footer"> <div class="footer-info"><p><a href="/baidusitemap.xml">网站地图</a> |  <a href="/atom.xml">订阅本站</a> |  <a href="/about/">联系博主</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次，本站总访客数:<i id="busuanzi_container_site_uv"><i id="busuanzi_value_site_uv"></i></i>人</p><p><span> Copyright &copy;<a href="/." rel="nofollow">暗也橙子.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/zzuUriel/zzuUriel.github.io"> BlueLake.</a></span><span> Count by<a href="http://busuanzi.ibruce.info/"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/javascript" src="/js/search.json.js?v=2.0.5"></script><div id="fullscreen-img" class="hide"><span class="close"></span></div><script type="text/javascript" src="/js/imgview.js?v=2.0.5" async></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.5" async></script><link rel="stylesheet" type="text/css" href="/share/css/share.css"><script type="text/javascript" src="/share/js/social-share.js" charset="utf-8"></script><script type="text/javascript" src="/share/js/qrcode.js" charset="utf-8"></script></body></html>